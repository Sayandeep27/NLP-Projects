{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxBEHboxHAMSXPM4SmuM8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayandeep27/NLP-Projects/blob/main/Generating_Text_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XYLwTIXfWYYB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
        "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAAd0POOWcL1",
        "outputId": "0b880fea-6e84-47e8-e8bf-8832875bc11e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
      ],
      "metadata": {
        "id": "KcBgRso6Wnc9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text[300000:800000]"
      ],
      "metadata": {
        "id": "HTjumSHmWqcV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "metadata": {
        "id": "smbPeGWWWrNk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_char = []"
      ],
      "metadata": {
        "id": "oGHhroiKWtO3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text[i + SEQ_LENGTH])"
      ],
      "metadata": {
        "id": "mbHOnzyZWvqa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
        "              len(characters)), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences),\n",
        "              len(characters)), dtype=np.bool_)"
      ],
      "metadata": {
        "id": "V1qLfZ2UWyM_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ],
      "metadata": {
        "id": "kWR8s1bZW1za"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Activation, Dense, LSTM"
      ],
      "metadata": {
        "id": "HY2lzLU4XEp1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,\n",
        "               input_shape=(SEQ_LENGTH,\n",
        "                            len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmgsE9WzXHSc",
        "outputId": "01bfdc7a-0c48-40ec-a3ae-8b0c6be3ac47"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.01))\n",
        "\n",
        "model.fit(x, y, batch_size=256, epochs=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b911_VayXJaZ",
        "outputId": "acbe2ac0-0039-4e94-87c3-05ecda6097f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 152ms/step - loss: 2.4831\n",
            "Epoch 2/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 168ms/step - loss: 1.7620\n",
            "Epoch 3/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 171ms/step - loss: 1.6014\n",
            "Epoch 4/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 159ms/step - loss: 1.5243\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c6cd3b57f90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "0GTLOpzvXMcI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "metadata": {
        "id": "g4DKYnfjXbdM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.2))\n",
        "print(generate_text(300, 0.4))\n",
        "print(generate_text(300, 0.5))\n",
        "print(generate_text(300, 0.6))\n",
        "print(generate_text(300, 0.7))\n",
        "print(generate_text(300, 0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vELu1LYRXcP7",
        "outputId": "685e8e5a-11fd-4140-c87e-1435c598fbdc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "that thou hast shown\n",
            "doth add more griefs of the streak the crown,\n",
            "the wars the bear the bear the bear the brother,\n",
            "the strength of the rown the strength a bear the creath,\n",
            "the bear the face the strength a send the corm\n",
            "the both the bear the son the streak the stay\n",
            "the both the starl the true the both the bears,\n",
            "and the bear the both the \n",
            "ienced, which no less adorns\n",
            "our gentry and the ways and the challing:\n",
            "the change the streak the send the keeps,\n",
            "and the friends the this the beak as the cormon\n",
            "what the think the both streak his mester,\n",
            "and so and as my lord, the forth, the kings\n",
            "sweet my bolong the king the bear the fort\n",
            "the grave a dutter the charring of my soul to my \n",
            "!\n",
            "alla stoccata carries it away.\n",
            "tybalt, in the ray the sack of the bear thee\n",
            "here but the way of the pown the wair.\n",
            "\n",
            "there mercus:\n",
            "the beath of him her sone the trusm his chairing as the duke of then be son,\n",
            "the see the to, shall be not not the treath:\n",
            "go die not the frather, the she here, the corse,\n",
            "to see the bolk of mine estress's hin\n",
            "le warwick?\n",
            "and when came george from but pains; thou shall say\n",
            "i life dear this down report,\n",
            "the baster than all of the parsunce propin:\n",
            "and mercivil then will of was a to the love,\n",
            "and be the care it she ell the bown thee\n",
            "here i have die stard but creathes mather's worth,\n",
            "and the bloody of the rest that i see and son\n",
            "whither than the tu\n",
            "ay, no; no, ay; for i must nothing be;\n",
            "the bend sorrow of hold the keeps,\n",
            "and and her limber deens the think which they sam\n",
            "i' the rongury double is his take a dut:\n",
            "that there sure the king while that hath\n",
            "ruse be think for the bosament with thee he\n",
            "shall the grueds now my doth to keep thee to john:\n",
            "i care her you will my sun her at herch\n",
            "state to-morrow:\n",
            "so please you, let me not it never blood,\n",
            "for a honour'd a morrow on greats a dase\n",
            "their speak that are mather, stay doth subjects;\n",
            "whither three man may buspise a gloucester!\n",
            "\n",
            "whom staped:\n",
            "be shall have whep paurs? now?\n",
            "\n",
            "armiven:\n",
            "\n",
            "romeo:\n",
            "but such i same as be why tears; which free.\n",
            "sir, but lords, for new contrity of lan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hSXNaTArXcVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8DNQ6FNDXcXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qCJaFrpfXcbL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}